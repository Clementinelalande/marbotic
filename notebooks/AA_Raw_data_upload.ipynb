{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7ac76a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17abcb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T09:38:18.230643Z",
     "start_time": "2022-07-20T09:38:17.745124Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "#Imports Bigquery\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae642fc",
   "metadata": {},
   "source": [
    "## GCP config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55028ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T09:38:18.234149Z",
     "start_time": "2022-07-20T09:38:18.232280Z"
    }
   },
   "outputs": [],
   "source": [
    "#Localisation du projet name et table_id sur gcp\n",
    "#TODO : Remplacer le nom du projet et du dataset sur GCP \n",
    "project=\"marbotic\"\n",
    "dataset = \"marbotic_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac270c21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T09:38:18.238214Z",
     "start_time": "2022-07-20T09:38:18.235215Z"
    }
   },
   "outputs": [],
   "source": [
    "#intégration des credentials\n",
    "#TODO : Remplacer le path de credential d'accès à notre projet GCP\n",
    "key_path = \"/Users/antonin/code/AntoninAnq/gcp/marbotic-7d02fac30bd8.json\"\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b52dc71",
   "metadata": {},
   "source": [
    "## Preprocessin du JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "172a5ed1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T09:38:18.241485Z",
     "start_time": "2022-07-20T09:38:18.239889Z"
    }
   },
   "outputs": [],
   "source": [
    "#conversion du fichier json en json line delimiter pour utiliser pd.read_json avec une chunk size. (Nombre de ligne processée en une fois)\n",
    "#!cat ../raw_data/export_23-5_minified.json | jq -c '.[]' > ../raw_data/export_converted_2.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff1156",
   "metadata": {},
   "source": [
    "## GCP upload table events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9baf8e68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T09:38:18.244408Z",
     "start_time": "2022-07-20T09:38:18.242580Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO : Remplacer la localisation des données sources\n",
    "FILE_PATH = '../raw_data/export_converted_2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b2756ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T12:46:53.755984Z",
     "start_time": "2022-07-20T12:46:53.737219Z"
    }
   },
   "outputs": [],
   "source": [
    "def upload_events_table(path,credentials, project,dataset,table):\n",
    "    CHUNKSIZE = 100000\n",
    "    table_id = f\"{dataset}.{table}\"\n",
    "    df = pd.read_json(path, lines=True, chunksize=CHUNKSIZE) #Chunk size pour avoir 14 chunk\n",
    "    \n",
    "    client = bigquery.Client(project,credentials)\n",
    "    \n",
    "    for i,c in enumerate(df):\n",
    "        index_init = np.linspace(1,len(c),len(c),dtype='int32')\n",
    "        ep=pd.DataFrame()\n",
    "        c.reset_index(inplace=True)\n",
    "        ep=c.copy()\n",
    "        ep.drop(['user_properties','event_properties'],axis=1,inplace=True)\n",
    "        ep['user_id'] = ep['user_id'].apply(lambda x: 0 if (x is None or type(x)== str or  np.isnan(x)) else int(x))\n",
    "        ep['id'] = (i*CHUNKSIZE) + index_init\n",
    "        ep.drop(['index'],axis=1,inplace=True)\n",
    "        #ep.to_csv('../raw_data/events.csv',index=False)\n",
    "        job = client.load_table_from_dataframe(ep, table_id) \n",
    "        job.result()  # Wait for the job to complete.\n",
    "        table = client.get_table(table_id)  # Make an API request.\n",
    "        print(\n",
    "            \"Loaded {} rows and {} columns to {}\".format(\n",
    "                table.num_rows, len(table.schema), table_id\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "460a9403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T12:47:09.993166Z",
     "start_time": "2022-07-20T12:46:55.443806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 rows and 15 columns to marbotic_dataset.events_f\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#TODO : Uncomment this line if you need to upload again events table\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mupload_events_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFILE_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevents_f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mupload_events_table\u001b[0;34m(path, credentials, project, dataset, table)\u001b[0m\n\u001b[1;32m     16\u001b[0m ep\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#ep.to_csv('../raw_data/events.csv',index=False)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_id\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     19\u001b[0m job\u001b[38;5;241m.\u001b[39mresult()  \u001b[38;5;66;03m# Wait for the job to complete.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m table \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_table(table_id)  \u001b[38;5;66;03m# Make an API request.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/google/cloud/bigquery/client.py:2702\u001b[0m, in \u001b[0;36mClient.load_table_from_dataframe\u001b[0;34m(self, dataframe, destination, num_retries, job_id, job_id_prefix, location, project, job_config, parquet_compression, timeout)\u001b[0m\n\u001b[1;32m   2700\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(tmppath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tmpfile:\n\u001b[1;32m   2701\u001b[0m         file_size \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(tmppath)\n\u001b[0;32m-> 2702\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtmpfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2706\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrewind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2707\u001b[0m \u001b[43m            \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2709\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_id_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_id_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2710\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2714\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2716\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2717\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(tmppath)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/google/cloud/bigquery/client.py:2451\u001b[0m, in \u001b[0;36mClient.load_table_from_file\u001b[0;34m(self, file_obj, destination, rewind, size, num_retries, job_id, job_id_prefix, location, project, job_config, timeout)\u001b[0m\n\u001b[1;32m   2447\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_resumable_upload(\n\u001b[1;32m   2448\u001b[0m             file_obj, job_resource, num_retries, timeout, project\u001b[38;5;241m=\u001b[39mproject\n\u001b[1;32m   2449\u001b[0m         )\n\u001b[1;32m   2450\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2451\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_multipart_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_resource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\n\u001b[1;32m   2453\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m resumable_media\u001b[38;5;241m.\u001b[39mInvalidResponse \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   2455\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(exc\u001b[38;5;241m.\u001b[39mresponse)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/google/cloud/bigquery/client.py:3021\u001b[0m, in \u001b[0;36mClient._do_multipart_upload\u001b[0;34m(self, stream, metadata, size, num_retries, timeout, project)\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_retries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3017\u001b[0m     upload\u001b[38;5;241m.\u001b[39m_retry_strategy \u001b[38;5;241m=\u001b[39m resumable_media\u001b[38;5;241m.\u001b[39mRetryStrategy(\n\u001b[1;32m   3018\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39mnum_retries\n\u001b[1;32m   3019\u001b[0m     )\n\u001b[0;32m-> 3021\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mupload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransmit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_http\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_GENERIC_CONTENT_TYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   3023\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/google/resumable_media/requests/upload.py:153\u001b[0m, in \u001b[0;36mMultipartUpload.transmit\u001b[0;34m(self, transport, data, metadata, content_type, timeout)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(result)\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_request_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_and_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriable_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_status_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_strategy\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/google/resumable_media/requests/_request_helpers.py:148\u001b[0m, in \u001b[0;36mwait_and_retry\u001b[0;34m(func, get_status_code, retry_strategy)\u001b[0m\n\u001b[1;32m    146\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _CONNECTION_ERROR_CLASSES \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    150\u001b[0m     error \u001b[38;5;241m=\u001b[39m e  \u001b[38;5;66;03m# Fall through to retry, if there are retries left.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/google/resumable_media/requests/upload.py:145\u001b[0m, in \u001b[0;36mMultipartUpload.transmit.<locals>.retriable_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretriable_request\u001b[39m():\n\u001b[0;32m--> 145\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(result)\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/google/auth/transport/requests.py:490\u001b[0m, in \u001b[0;36mAuthorizedSession.request\u001b[0;34m(self, method, url, data, headers, max_allowed_time, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m remaining_time \u001b[38;5;241m=\u001b[39m guard\u001b[38;5;241m.\u001b[39mremaining_timeout\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TimeoutGuard(remaining_time) \u001b[38;5;28;01mas\u001b[39;00m guard:\n\u001b[0;32m--> 490\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAuthorizedSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m remaining_time \u001b[38;5;241m=\u001b[39m guard\u001b[38;5;241m.\u001b[39mremaining_timeout\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/envs/marbotic/lib/python3.8/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/http/client.py:1348\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1350\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TODO : Uncomment this line if you need to upload again events table\n",
    "#upload_events_table(FILE_PATH,credentials, project,dataset,\"events_f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ef89c",
   "metadata": {},
   "source": [
    "## GCP upload table user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634ba676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T12:47:16.811172Z",
     "start_time": "2022-07-20T12:47:16.807337Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO : Remplacer la localisation des données sources\n",
    "FILE_PATH_USER_ID = '../raw_data/users_info_202206071551.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ac62c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T13:11:57.551822Z",
     "start_time": "2022-07-20T13:11:57.529238Z"
    }
   },
   "outputs": [],
   "source": [
    "def upload_user_id_table(path,credentials, project,dataset,table):\n",
    "    CHUNKSIZE = 5000\n",
    "    \n",
    "    table_id = f\"{dataset}.{table}\"\n",
    "    df = pd.read_csv(path,chunksize=CHUNKSIZE,sep=\";\")\n",
    "    client = bigquery.Client(project,credentials)\n",
    "    \n",
    "    for i,c in enumerate(df):\n",
    "        ep=pd.DataFrame()\n",
    "        c.reset_index(inplace=True)\n",
    "        ep=c.copy()\n",
    "        ep.drop(['Country','Language','News letter','Type','Games','Products','Pieces','index'],axis=1,inplace=True)\n",
    "        ep.rename(columns={'User id':'User_id'},inplace=True)\n",
    "    \n",
    "        cat = ep['Purchases'].copy().map(lambda x: \", \".join(x)\n",
    "                                            if isinstance(x, list) else x)\n",
    "        names = list(\n",
    "            set([\n",
    "                x.strip().strip(\"'\").strip(\"['\")\n",
    "                for x in ', '.join(', '.join(', '.join(\n",
    "                    list(set([str(x) for x in cat]))).split('\\n')).split(\n",
    "                        \"' '\")).split(',')\n",
    "            ]))\n",
    "    \n",
    "        names_transf = [\n",
    "            'Purchases' + '_' + x.replace(' ', '_').replace(']', '').replace('\"', '') for x in names\n",
    "            if x != 'nan' and x != ''\n",
    "        ]\n",
    "        names = [x for x in names if x != 'nan' and x != '']\n",
    "        for ind, name in enumerate(names_transf):\n",
    "            ep[f'{name}'] = ep['Purchases'].map(\n",
    "                lambda x: 1 if isinstance(x, str) and f'{names[ind]}' in x else\n",
    "                (1 if isinstance(x, list) and\n",
    "                 len([n for n in x if f'{names[ind]}' in n]) > 0\n",
    "                 else 0))\n",
    "            \n",
    "        ep.drop(['Purchases'],axis=1,inplace=True)\n",
    "            \n",
    "        job = client.load_table_from_dataframe(ep, table_id)  \n",
    "        job.result()  \n",
    "        table = client.get_table(table_id)\n",
    "        print(\n",
    "            \"Loaded {} rows and {} columns to {}\".format(\n",
    "                table.num_rows, len(table.schema), table_id\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b1ba91e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T12:47:45.106903Z",
     "start_time": "2022-07-20T12:47:23.975369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5000 rows and 13 columns to marbotic_dataset.user_id_f\n",
      "Loaded 10000 rows and 13 columns to marbotic_dataset.user_id_f\n",
      "Loaded 13679 rows and 13 columns to marbotic_dataset.user_id_f\n"
     ]
    }
   ],
   "source": [
    "#TODO : Uncomment this line if you need to upload again user_id table\n",
    "#upload_user_id_table(FILE_PATH_USER_ID,credentials, project,dataset,\"user_id_f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fb5714",
   "metadata": {},
   "source": [
    "**Creation de la colonne purchases**\n",
    "\n",
    "On créé une colonne \"purchases\" pour spécifier si l'utilisateur à déjà acheté au moins un produit.  \n",
    "On le fait via la console GCP avec les commande SQL ci dessous.  \n",
    "\n",
    "Dans un premier temps on doit créé la colonne \"purchases\" de type booléen qui sera vide.  \n",
    "Puis on initialise toutes les valeurs à False avec la requête ci dessous.\n",
    "\n",
    "```   \n",
    "UPDATE `marbotic.marbotic_dataset.user_id_f`  \n",
    "SET purchases = False  \n",
    "WHERE TRUE  \n",
    "```\n",
    "\n",
    "\n",
    "Enfin on mets à jour les profils utilisateurs ayant effectué au moins un achat avec la requête ci dessous.  \n",
    "\n",
    "```\n",
    "UPDATE `marbotic.marbotic_dataset.user_id_f`   \n",
    "SET purchases = True  \n",
    "WHERE Purchases_PY1Y = 1  \n",
    "OR  \n",
    "Purchases_PLY = 1  \n",
    "OR   \n",
    "Purchases_MEGR = 1  \n",
    "OR  \n",
    "Purchases_PLM = 1  \n",
    "OR   \n",
    "Purchases_ME1 = 1  \n",
    "OR   \n",
    "Purchases_EY3M = 1  \n",
    "OR  \n",
    "Purchases_tier_upgrade_0_to_1 = 1  \n",
    "OR  \n",
    "Purchases_PM3M = 1  \n",
    "OR  \n",
    "Purchases_MPGR = 1  \n",
    "OR  \n",
    "Purchases_EY1Y = 1  \n",
    "OR  \n",
    "Purchases_PY3M = 1  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c64e9",
   "metadata": {},
   "source": [
    "## GCP upload user_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c86545e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T13:30:13.080866Z",
     "start_time": "2022-07-20T13:30:13.045043Z"
    }
   },
   "outputs": [],
   "source": [
    "def upload_user_properties_table(path,credentials, project,dataset,table):\n",
    "\n",
    "    CHUNKSIZE = 100000\n",
    "    table_id = f\"{dataset}.{table}\"\n",
    "    df = pd.read_json(path, lines=True, chunksize=CHUNKSIZE) #Chunk size pour avoir 14 chunk\n",
    "    \n",
    "    client = bigquery.Client(project,credentials)\n",
    "    \n",
    "    for i,c in enumerate(df):\n",
    "        index_init = np.linspace(1,len(c),len(c),dtype='int32')\n",
    "        ep=pd.DataFrame()\n",
    "        c.reset_index(inplace=True)\n",
    "        ep=pd.DataFrame(c[\"user_properties\"].to_list()).copy()\n",
    "    \n",
    "        for col_concat in ['Products', 'Pieces', 'Games']:\n",
    "            cat = ep[f'{col_concat}'].copy().map(lambda x: \", \".join(x)\n",
    "                                                if isinstance(x, list) else x)\n",
    "            names = list(\n",
    "                set([\n",
    "                    x.strip().strip(\"'\").strip(\"['\")\n",
    "                    for x in ', '.join(', '.join(', '.join(\n",
    "                        list(set([str(x) for x in cat]))).split('\\n')).split(\n",
    "                            \"' '\")).split(',')\n",
    "                ]))\n",
    "            names_transf = [\n",
    "                col_concat + '_' + x.replace(' ', '_') for x in names\n",
    "                if x != 'nan' and x != ''\n",
    "            ]\n",
    "            names = [x for x in names if x != 'nan' and x != '']\n",
    "            for ind, name in enumerate(names_transf):\n",
    "    \n",
    "                ep[f'{name}'] = ep[f'{col_concat}'].map(\n",
    "                    lambda x: 1 if isinstance(x, str) and f'{names[ind]}' in x else\n",
    "                    (1 if isinstance(x, list) and\n",
    "                     len([n for n in x if f'{names[ind]}' in n]) > 0\n",
    "                     else 0))\n",
    "    \n",
    "        ep.drop(['Products', 'Pieces', 'Games'], axis=1, inplace=True)\n",
    "        ep['event_id']=c[\"event_id\"].copy()\n",
    "        ep['client_event_time']=c['client_event_time'].copy()\n",
    "        ep['user_creation_time']=c['user_creation_time'].copy()\n",
    "        ep['user_id']=c['user_id'].copy()\n",
    "        ep['user_id'] = ep['user_id'].apply(lambda x: 0 if (x is None or type(x)== str or  np.isnan(x)) else int(x))\n",
    "        ep['id'] = (i*CHUNKSIZE) + index_init\n",
    "        \n",
    "        job_config = bigquery.LoadJobConfig()\n",
    "        job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
    "        job_config.schema_update_options = [\n",
    "        bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION\n",
    "        ]\n",
    "        \n",
    "        job = client.load_table_from_dataframe(ep, table_id, job_config=job_config)\n",
    "        job.result()  \n",
    "        table = client.get_table(table_id)  \n",
    "        print(\n",
    "            \"Loaded {} rows and {} columns to {}\".format(\n",
    "                table.num_rows, len(table.schema), table_id\n",
    "            )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48e8b36d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T13:34:48.039298Z",
     "start_time": "2022-07-20T13:30:13.973563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 rows and 39 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 200000 rows and 39 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 300000 rows and 39 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 400000 rows and 39 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 500000 rows and 40 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 600000 rows and 40 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 700000 rows and 40 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 800000 rows and 40 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 900000 rows and 40 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 1000000 rows and 40 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 1100000 rows and 40 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 1200000 rows and 40 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 1300000 rows and 40 columns to marbotic_dataset.user_properties_f\n",
      "Loaded 1320229 rows and 40 columns to marbotic_dataset.user_properties_f\n"
     ]
    }
   ],
   "source": [
    "#TODO : Uncomment this line if you need to upload again user_properties table\n",
    "#upload_user_properties_table(FILE_PATH,credentials, project,dataset,\"user_properties_f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284bab61",
   "metadata": {},
   "source": [
    "## GCP upload event_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a456d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T13:43:35.923399Z",
     "start_time": "2022-07-20T13:43:35.909788Z"
    }
   },
   "outputs": [],
   "source": [
    "#Update columns name for big query acceptance\n",
    "columns_rename = {'[Game] Code':'Game_Code','[Profile] Age (days)':'Profile_Age_days','[Scene] Name':'Scene_Name',\n",
    "                 '[Game] Language':'Game_Language', '[Scene] Previous':'Scene_Previous', '[Time] Spent':'Time_Spent',\n",
    "                  '[Scene] Next':'Scene_Next', '[Action] Element Type':'Action_Element_Type',\n",
    "                  '[Scene] Section':'Scene_Section', '[Action] Element Name':'Action_Element_Name',\n",
    "                 '[Activity] Name':'Activity_Name', '[Scaffolding] Level':'Scaffolding_Level',\n",
    "                  '[Game] Piece Code':'Game_Piece_Code','[Activity] Nb Wrong Answer':'Activity_Nb_Wrong_Answer',\n",
    "                  '[Activity] Solved':'Activity_Solved','[Activity] Piece Stamped':'Activity_Piece_Stamped',\n",
    "                  '[Activity] Piece Asked':'Activity_Piece_Asked','[Activity] Modality':'Activity_Modality',\n",
    "                  '[Time] Slot':'Time_Slot', '[Error] Type':'Error_Type',\n",
    "                  '[Activation] Game Code':'Activation_Game_Code',\n",
    "                  '[Activation] Product Code':'Activation_Product_Code',\n",
    "                 '[Activation] Piece Code':'Activation_Piece_Code', '[Popup] Name':'Popup_Name',\n",
    "                  '[Renewal] Type':'Renewal_Type','[Key] Type':'Key_Type','[Toast] Name':'Toast_Name'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6504c73d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T13:43:38.891481Z",
     "start_time": "2022-07-20T13:43:38.664306Z"
    }
   },
   "outputs": [],
   "source": [
    "def upload_event_properties_table(path,credentials, project,dataset,table):\n",
    "    CHUNKSIZE = 100000\n",
    "    \n",
    "    table_id = f\"{dataset}.{table}\"\n",
    "    df = pd.read_json(path, lines=True, chunksize=CHUNKSIZE) #Chunk size pour avoir 14 chunk\n",
    "    \n",
    "    client = bigquery.Client(project,credentials)\n",
    "    \n",
    "    for i,c in enumerate(df):\n",
    "        index_init = np.linspace(1,len(c),len(c),dtype='int32')\n",
    "        ep=pd.DataFrame()\n",
    "        c.reset_index(inplace=True)\n",
    "        ep=pd.DataFrame(c[\"event_properties\"].to_list()).copy()\n",
    "        ep['event_id']=c[\"event_id\"].copy()\n",
    "        ep['event_type']=c[\"event_type\"].copy()\n",
    "        ep['session_id']=c[\"session_id\"].copy()\n",
    "        ep['id'] = (i*CHUNKSIZE) + index_init\n",
    "        ep.rename(columns=columns_rename,inplace=True)\n",
    "        #ep.to_csv('../raw_data/event_properties.csv',index=False)\n",
    "        \n",
    "        job_config = bigquery.LoadJobConfig()\n",
    "        job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
    "        job_config.schema_update_options = [\n",
    "        bigquery.SchemaUpdateOption.ALLOW_FIELD_ADDITION\n",
    "        ]\n",
    "        \n",
    "        job = client.load_table_from_dataframe(ep, table_id,job_config=job_config)  \n",
    "        job.result()  \n",
    "        table = client.get_table(table_id) \n",
    "        print(\n",
    "            \"Loaded {} rows and {} columns to {}\".format(\n",
    "                table.num_rows, len(table.schema), table_id\n",
    "            )\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43ea7150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-20T13:46:01.980329Z",
     "start_time": "2022-07-20T13:43:43.864942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 rows and 28 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 200000 rows and 28 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 300000 rows and 28 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 400000 rows and 28 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 500000 rows and 28 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 600000 rows and 28 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 700000 rows and 29 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 800000 rows and 30 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 900000 rows and 30 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 1000000 rows and 30 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 1100000 rows and 31 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 1200000 rows and 31 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 1300000 rows and 31 columns to marbotic_dataset.event_properties_f\n",
      "Loaded 1320229 rows and 31 columns to marbotic_dataset.event_properties_f\n"
     ]
    }
   ],
   "source": [
    "#TODO : Uncomment this line if you need to upload again event_properties table\n",
    "#upload_event_properties_table(FILE_PATH,credentials, project,dataset,\"event_properties_f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd63f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
