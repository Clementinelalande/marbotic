{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aa0e4ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T12:59:45.235847Z",
     "start_time": "2022-06-09T12:59:44.769956Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e7b577",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T12:59:45.443195Z",
     "start_time": "2022-06-09T12:59:45.437731Z"
    }
   },
   "outputs": [],
   "source": [
    "#conversion du fichier json en json line delimiter pour utiliser pd.read_json avec une chunk size. (Nombre de ligne processée en une fois)\n",
    "#!cat ../raw_data/export_23-5_minified.json | jq -c '.[]' > ../raw_data/export_converted_2.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e9d77a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T12:59:46.057553Z",
     "start_time": "2022-06-09T12:59:46.053523Z"
    }
   },
   "outputs": [],
   "source": [
    "#Nombre de lignes totales dans le JSON : 1320229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1565e601",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T12:59:47.002591Z",
     "start_time": "2022-06-09T12:59:46.988927Z"
    }
   },
   "outputs": [],
   "source": [
    "#intégration des credentials\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "project = \"marbotic\"\n",
    "key_path = \"/Users/antonin/code/AntoninAnq/gcp/marbotic-7d02fac30bd8.json\"\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae0f1dbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-09T16:19:06.044346Z",
     "start_time": "2022-06-09T16:16:03.847968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 200000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 300000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 400000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 500000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 600000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 700000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 800000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 900000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 1000000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 1100000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 1200000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 1300000 rows and 40 columns to marbotic_dataset.user_properties\n",
      "Loaded 1320229 rows and 40 columns to marbotic_dataset.user_properties\n"
     ]
    }
   ],
   "source": [
    "CHUNKSIZE = 100000\n",
    "table_id = \"marbotic_dataset.user_properties\"\n",
    "\n",
    "file_path = '../raw_data/export_converted_2.json'\n",
    "df = pd.read_json(file_path, lines=True, chunksize=CHUNKSIZE) #Chunk size pour avoir 14 chunk\n",
    "\n",
    "client = bigquery.Client(project,credentials)\n",
    "\n",
    "for i,c in enumerate(df):\n",
    "    index_init = np.linspace(1,len(c),len(c),dtype='int32')\n",
    "    ep=pd.DataFrame()\n",
    "    c.reset_index(inplace=True)\n",
    "    ep=pd.DataFrame(c[\"user_properties\"].to_list()).copy()\n",
    "\n",
    "    for col_concat in ['Products', 'Pieces', 'Games']:\n",
    "        cat = ep[f'{col_concat}'].copy().map(lambda x: \", \".join(x)\n",
    "                                            if isinstance(x, list) else x)\n",
    "        names = list(\n",
    "            set([\n",
    "                x.strip().strip(\"'\").strip(\"['\")\n",
    "                for x in ', '.join(', '.join(', '.join(\n",
    "                    list(set([str(x) for x in cat]))).split('\\n')).split(\n",
    "                        \"' '\")).split(',')\n",
    "            ]))\n",
    "        names_transf = [\n",
    "            col_concat + '_' + x.replace(' ', '_') for x in names\n",
    "            if x != 'nan' and x != ''\n",
    "        ]\n",
    "        names = [x for x in names if x != 'nan' and x != '']\n",
    "        for ind, name in enumerate(names_transf):\n",
    "\n",
    "            ep[f'{name}'] = ep[f'{col_concat}'].map(\n",
    "                lambda x: 1 if isinstance(x, str) and f'{names[ind]}' in x else\n",
    "                (1 if isinstance(x, list) and\n",
    "                 len([n for n in x if f'{names[ind]}' in n]) > 0\n",
    "                 else 0))\n",
    "            #ep['test']=ep[f'{col_concat}'].str.replace('[^\\w\\s\\d]', '', regex=True)\n",
    "\n",
    "    ep.drop(['Products', 'Pieces', 'Games'], axis=1, inplace=True)\n",
    "    ep['event_id']=c[\"event_id\"].copy()\n",
    "    ep['client_event_time']=c['client_event_time'].copy()\n",
    "    ep['user_creation_time']=c['user_creation_time'].copy()\n",
    "    ep['user_id']=c['user_id'].copy()\n",
    "    ep['user_id'] = ep['user_id'].apply(lambda x: 0 if (x is None or type(x)== str or  np.isnan(x)) else int(x))\n",
    "    ep['id'] = (i*CHUNKSIZE) + index_init\n",
    "    job = client.load_table_from_dataframe(ep, table_id)\n",
    "    job.result()  # Wait for the job to complete.\n",
    "    table = client.get_table(table_id)  # Make an API request.\n",
    "    print(\n",
    "        \"Loaded {} rows and {} columns to {}\".format(\n",
    "            table.num_rows, len(table.schema), table_id\n",
    "        )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152508bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add_manually = ['Products_Sensory_kit'] #integer\n",
    "query = f\"DELETE FROM `{table_id}` WHERE true\"\n",
    "query_job = client.query(query)\n",
    "results=query_job.result().to_dataframe()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83157318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "716756f4d79260a81a518c6b1f5f51749786bf8e48d1fc9146fc241b6cd607b3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
